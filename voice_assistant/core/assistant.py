#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯­éŸ³åŠ©æ‰‹æ ¸å¿ƒæ¨¡å—
ä¸»è¦ä¸šåŠ¡é€»è¾‘å’Œå¯¹è¯æ§åˆ¶
"""

import os
import re
import tempfile
import time
import threading
from typing import Optional

from ..config import config
from ..audio.recorder import AudioRecorder, is_audio_available, RecordingMode, record_audio
from ..audio.tts import create_tts_manager
from ..speech.baidu_asr import create_baidu_asr
from ..chat.deepseek import create_deepseek_chat


class VoiceAssistant:
    """è¯­éŸ³åŠ©æ‰‹ä¸»ç±»"""

    def __init__(self,
                 use_baidu_tts: bool = False,
                 initial_volume: int = None,
                 voice_person: int = None,
                 recording_mode: str = "smart_vad"):
        """
        åˆå§‹åŒ–è¯­éŸ³åŠ©æ‰‹

        Args:
            use_baidu_tts: æ˜¯å¦ä½¿ç”¨ç™¾åº¦TTS
            initial_volume: åˆå§‹éŸ³é‡
            voice_person: è¯­éŸ³äººç‰©
            recording_mode: å½•éŸ³æ¨¡å¼ (smart_vad, enter_key, fixed_duration)
        """
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.chat = create_deepseek_chat()
        self.recorder = AudioRecorder() if is_audio_available() else None
        self.speech_recognizer = create_baidu_asr()
        self.tts = create_tts_manager(
            use_baidu=use_baidu_tts,
            voice_person=voice_person,
            initial_volume=initial_volume
        )

        # å½•éŸ³æ¨¡å¼è®¾ç½®
        self.recording_mode = recording_mode

        # èˆè¹ˆå‘½ä»¤å¤„ç†å™¨
        self.dance_handler = None
        self._validate_recording_mode()



        # è¯­éŸ³å¯¹è¯æ§åˆ¶
        self.voice_chat_active = True

        # è·³èˆæ¨¡å¼æ§åˆ¶
        self.in_dance_mode = False
        self.dance_paused = False  # è·³èˆæ—¶æš‚åœè¯­éŸ³è¯†åˆ«

        if not self.chat:
            raise RuntimeError("æ— æ³•åˆå§‹åŒ–DeepSeekèŠå¤©å®¢æˆ·ç«¯")

        if not self.speech_recognizer:
            raise RuntimeError("æ— æ³•åˆå§‹åŒ–ç™¾åº¦è¯­éŸ³è¯†åˆ«")

        if not self.recorder:
            raise RuntimeError("æ— æ³•åˆå§‹åŒ–å½•éŸ³å™¨")

        # å¯åŠ¨æ—¶æ¸…ç†æ—§å½•éŸ³æ–‡ä»¶
        self._startup_cleanup()

    def set_dance_handler(self, handler):
        """è®¾ç½®èˆè¹ˆå‘½ä»¤å¤„ç†å™¨"""
        self.dance_handler = handler

    def _validate_recording_mode(self):
        """éªŒè¯å½•éŸ³æ¨¡å¼"""
        valid_modes = ["smart_vad", "enter_key", "fixed_duration"]
        if self.recording_mode not in valid_modes:
            print(f"âš ï¸ æ— æ•ˆçš„å½•éŸ³æ¨¡å¼: {self.recording_mode}")
            print(f"   æ”¯æŒçš„æ¨¡å¼: {valid_modes}")
            print("   ä½¿ç”¨é»˜è®¤æ¨¡å¼: smart_vad")
            self.recording_mode = "smart_vad"
    
    def run_voice_chat(self):
        """è¿è¡Œè¯­éŸ³å¯¹è¯"""
        if not is_audio_available():
            print("âŒ éŸ³é¢‘åŠŸèƒ½ä¸å¯ç”¨")
            return
        
        self._print_welcome_message()
        
        conversation_count = 0
        
        try:
            while self.voice_chat_active:
                # æ£€æŸ¥æ˜¯å¦åœ¨è·³èˆæ¨¡å¼ä¸‹æš‚åœ
                if self.dance_paused:
                    time.sleep(0.5)  # æš‚åœæœŸé—´çŸ­æš‚ä¼‘çœ 
                    continue

                conversation_count += 1
                print(f"\n[ç¬¬{conversation_count}è½®å¯¹è¯]")

                # å½•éŸ³ - ä½¿ç”¨æ›´å®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶ç®¡ç†
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False, dir='/tmp') as temp_file:
                    temp_filename = temp_file.name
                
                try:
                    # æ ¹æ®å½•éŸ³æ¨¡å¼é€‰æ‹©å½•éŸ³æ–¹æ³•
                    recording_success = self._record_audio(temp_filename)

                    if recording_success:
                        file_size = os.path.getsize(temp_filename)
                        if file_size < config.ASR_MIN_FILE_SIZE:
                            print("ğŸ”‡ æœªæ£€æµ‹åˆ°å£°éŸ³")
                            continue
                        
                        # è¯­éŸ³è¯†åˆ«
                        text = self.speech_recognizer.recognize_audio_file(temp_filename)

                        # ç«‹å³åˆ é™¤å½•éŸ³æ–‡ä»¶
                        self._delete_audio_file(temp_filename)

                        if not text:
                            print("âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥")
                            continue
                        
                        print(f"ğŸ‘¤ ä½ è¯´: {text}")

                        # å¤„ç†è¯­éŸ³å‘½ä»¤
                        if self._handle_voice_commands(text):
                            continue
                        
                        # è·å–AIå›å¤
                        response = self.chat.get_response(text)
                        if response:
                            print(f"ğŸ¤– AI: {response}")
                            # è¯­éŸ³æ’­æ”¾AIå›å¤
                            self.tts.speak(response)
                            # ç­‰å¾…æ’­æ”¾å®Œæˆå†è¿›å…¥ä¸‹ä¸€è½®å¯¹è¯
                            self.tts.wait_for_speech_complete()
                        else:
                            print("âŒ AIå›å¤å¤±è´¥")
                    
                    else:
                        print("âŒ å½•éŸ³å¤±è´¥")
                
                finally:
                    if os.path.exists(temp_filename):
                        os.remove(temp_filename)
        
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å¯¹è¯è¢«ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ å‡ºé”™: {e}")
        
        print(f"\nğŸ“Š å…±è¿›è¡Œäº† {conversation_count-1} è½®å¯¹è¯")

    def _record_audio(self, filename: str) -> bool:
        """æ ¹æ®å½•éŸ³æ¨¡å¼å½•éŸ³"""
        if self.recording_mode == "smart_vad":
            return self.recorder.record_with_smart_vad(filename)
        elif self.recording_mode == "enter_key":
            print("ğŸ¤ æŒ‰é”®æ§åˆ¶å½•éŸ³æ¨¡å¼")
            return self.recorder.record_with_enter_control(filename)
        elif self.recording_mode == "fixed_duration":
            print("ğŸ¤ å›ºå®šæ—¶é•¿å½•éŸ³æ¨¡å¼ (4ç§’)")
            return self.recorder.record_for_duration(4.0, filename)
        else:
            print(f"âŒ æœªçŸ¥å½•éŸ³æ¨¡å¼: {self.recording_mode}")
            return False

    def _print_welcome_message(self):
        """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
        print("\nğŸ¤ æ™ºèƒ½è¯­éŸ³èˆè¹ˆæœºå™¨äºº")
        print("ğŸ”§ ç™¾åº¦è¯­éŸ³è¯†åˆ« + DeepSeek AI + ç™¾åº¦TTS")
        print("\nğŸ’¡ è¯­éŸ³æ§åˆ¶å‘½ä»¤:")
        print("   ğŸ—£ï¸  åŸºç¡€å¯¹è¯: ç›´æ¥è¯´è¯å³å¯ä¸AIå¯¹è¯")
        print("   ğŸ’ƒ èˆè¹ˆæ§åˆ¶: 'çœŸå®è·³èˆXç§’' / 'æ¨¡æ‹Ÿè·³èˆXç§’' / 'åœæ­¢è·³èˆ'")
        print("   ğŸ­ å•ä¸ªåŠ¨ä½œ: 'æ‰§è¡ŒåŠ¨ä½œï¼šç«‹æ­£' / 'æ‰§è¡ŒåŠ¨ä½œï¼šå¤§åˆ›å‰è¿›' / 'åŠ¨ä½œåˆ—è¡¨'")
        print("   ğŸ”Š éŸ³é‡æ§åˆ¶: 'éŸ³é‡è°ƒé«˜' / 'éŸ³é‡è°ƒä½' / 'éŸ³é‡è®¾ç½®ä¸ºX'")
        print("   ğŸ”‡ è¯­éŸ³æ§åˆ¶: 'é™éŸ³' / 'å–æ¶ˆé™éŸ³' / 'è·³è¿‡æ’­æ”¾'")
        print("   ğŸ”„ ç³»ç»Ÿæ§åˆ¶: 'æ¸…ç©ºå†å²' / 'é€€å‡ºå¯¹è¯'")
        print("\nğŸ¤ å½•éŸ³æ¨¡å¼: æ™ºèƒ½VAD - è¯´è¯å³å¯å¼€å§‹å½•éŸ³ï¼Œåœæ­¢è¯´è¯è‡ªåŠ¨ç»“æŸ")
        print(f"ğŸ”Š å½“å‰éŸ³é‡: {self.tts.volume_level}/10")
        print("-" * 50)
    
    def _handle_voice_commands(self, text: str) -> bool:
        """å¤„ç†è¯­éŸ³å‘½ä»¤ï¼Œè¿”å›Trueè¡¨ç¤ºå‘½ä»¤å·²å¤„ç†ï¼Œè·³è¿‡AIå¯¹è¯"""
        text_lower = text.lower()

        # èˆè¹ˆå‘½ä»¤å¤„ç†ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        if self.dance_handler:
            if self.dance_handler.handle_voice_command(text_lower):
                return True

        # é€€å‡ºå‘½ä»¤
        if any(keyword in text_lower for keyword in config.EXIT_COMMANDS):
            print("ğŸ‘‹ å¯¹è¯ç»“æŸï¼")
            raise KeyboardInterrupt()
        
        # é™éŸ³å‘½ä»¤
        if any(keyword in text_lower for keyword in config.MUTE_COMMANDS):
            self.tts.toggle_mute()
            return True
        
        # å–æ¶ˆé™éŸ³å‘½ä»¤
        if any(keyword in text_lower for keyword in config.UNMUTE_COMMANDS):
            if self.tts.muted:
                self.tts.toggle_mute()
            else:
                self.tts.enabled = True
                print("ğŸ”Š AIè¯­éŸ³å·²å¼€å¯")
            self.tts.speak("è¯­éŸ³åŠŸèƒ½å·²å¼€å¯")
            return True
        
        # è·³è¿‡æ’­æ”¾å‘½ä»¤
        if any(keyword in text_lower for keyword in config.SKIP_COMMANDS):
            if self.tts.is_speaking:
                print("â­ï¸ è·³è¿‡å½“å‰AIè¯­éŸ³æ’­æ”¾")
                self.tts.stop_current_speech()
                print("âœ… å·²è·³è¿‡ï¼Œè¿›å…¥ä¸‹ä¸€è½®å¯¹è¯")
            else:
                print("ğŸ’¡ å½“å‰æ²¡æœ‰AIè¯­éŸ³æ’­æ”¾")
            return True
        
        # éŸ³é‡è°ƒé«˜å‘½ä»¤
        if any(keyword in text_lower for keyword in config.VOLUME_UP_COMMANDS):
            self.tts.volume_up()
            self.tts.speak(f"éŸ³é‡å·²è°ƒé«˜åˆ°{self.tts.volume_level}")
            return True
        
        # éŸ³é‡è°ƒä½å‘½ä»¤
        if any(keyword in text_lower for keyword in config.VOLUME_DOWN_COMMANDS):
            self.tts.volume_down()
            self.tts.speak(f"éŸ³é‡å·²è°ƒä½åˆ°{self.tts.volume_level}")
            return True
        
        # éŸ³é‡è®¾ç½®å‘½ä»¤
        volume_match = re.search(r'éŸ³é‡è®¾ç½®ä¸º(\d+)', text)
        if volume_match:
            volume = int(volume_match.group(1))
            if 1 <= volume <= 10:
                self.tts.set_volume(volume)
                self.tts.speak(f"éŸ³é‡å·²è®¾ç½®ä¸º{volume}")
            else:
                self.tts.speak("éŸ³é‡èŒƒå›´æ˜¯1åˆ°10")
            return True
        
        # æ¸…ç©ºå†å²å‘½ä»¤
        if any(keyword in text_lower for keyword in ['æ¸…ç©ºå†å²', 'é‡æ–°å¼€å§‹', 'æ¸…é™¤å†å²', 'æ–°å¯¹è¯']):
            self.chat.clear_history()
            self.tts.speak("å¯¹è¯å†å²å·²æ¸…ç©ºï¼Œæˆ‘ä»¬é‡æ–°å¼€å§‹å§")
            return True



        return False



    def stop_voice_chat(self):
        """åœæ­¢è¯­éŸ³å¯¹è¯"""
        self.voice_chat_active = False
        print("ğŸ›‘ è¯­éŸ³å¯¹è¯å·²åœæ­¢")

    def start_voice_chat_flag(self):
        """å¯åŠ¨è¯­éŸ³å¯¹è¯æ ‡å¿—"""
        self.voice_chat_active = True
        print("ğŸ¤ è¯­éŸ³å¯¹è¯å·²å¯åŠ¨")

    def set_dance_mode(self, enabled: bool):
        """è®¾ç½®è·³èˆæ¨¡å¼çŠ¶æ€"""
        self.in_dance_mode = enabled
        self.dance_paused = enabled  # è·³èˆæ—¶æš‚åœè¯­éŸ³è¯†åˆ«

        # æ§åˆ¶å½•éŸ³å™¨æš‚åœ/æ¢å¤
        if self.recorder and hasattr(self.recorder, '_smart_recorder') and self.recorder._smart_recorder:
            if enabled:
                self.recorder._smart_recorder.pause_recording()
            else:
                self.recorder._smart_recorder.resume_recording()

        if enabled:
            print("ğŸ”‡ è·³èˆæ¨¡å¼ï¼šè¯­éŸ³è¯†åˆ«å’Œå½•éŸ³å·²å®Œå…¨æš‚åœ")
        else:
            print("ğŸ¤ è·³èˆç»“æŸï¼šè¯­éŸ³è¯†åˆ«å’Œå½•éŸ³å·²æ¢å¤")



    def _delete_audio_file(self, filename: str):
        """åˆ é™¤å½•éŸ³æ–‡ä»¶"""
        try:
            if getattr(config, 'AUDIO_AUTO_DELETE', True) and os.path.exists(filename):
                os.unlink(filename)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤å½•éŸ³æ–‡ä»¶")

                # é¢å¤–æ¸…ç†ï¼šåˆ é™¤/tmpç›®å½•ä¸‹çš„å…¶ä»–ä¸´æ—¶å½•éŸ³æ–‡ä»¶
                import glob
                temp_files = glob.glob("/tmp/tmp*.wav")
                for temp_file in temp_files:
                    try:
                        # åªåˆ é™¤è¶…è¿‡5åˆ†é’Ÿçš„ä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…åˆ é™¤æ­£åœ¨ä½¿ç”¨çš„æ–‡ä»¶
                        import time
                        if time.time() - os.path.getmtime(temp_file) > 300:
                            os.unlink(temp_file)
                    except:
                        pass
        except Exception:
            # åˆ é™¤å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            pass

    def _startup_cleanup(self):
        """å¯åŠ¨æ—¶æ¸…ç†æ‰€æœ‰å½•éŸ³æ–‡ä»¶"""
        try:
            if not getattr(config, 'AUDIO_CLEANUP_ON_START', True):
                return

            from pathlib import Path
            import glob

            # æŸ¥æ‰¾å¹¶åˆ é™¤æ‰€æœ‰å½•éŸ³æ–‡ä»¶ï¼ˆåŒ…æ‹¬/tmpç›®å½•ï¼‰
            audio_patterns = ["*.wav", "*.mp3", "temp_*.wav", "recording_*.wav", "user_audio_*.wav"]
            search_dirs = [".", "/tmp"]
            deleted_count = 0

            for search_dir in search_dirs:
                for pattern in audio_patterns:
                    try:
                        if search_dir == "/tmp":
                            # åœ¨/tmpç›®å½•ä¸­æŸ¥æ‰¾ä¸´æ—¶å½•éŸ³æ–‡ä»¶
                            files = glob.glob(f"/tmp/tmp*.wav")
                        else:
                            files = list(Path(search_dir).glob(pattern))

                        for file_path in files:
                            try:
                                if isinstance(file_path, str):
                                    os.unlink(file_path)
                                else:
                                    file_path.unlink()
                                deleted_count += 1
                            except:
                                pass
                    except:
                        pass

            if deleted_count > 0:
                print(f"ğŸ—‘ï¸ å¯åŠ¨æ¸…ç†: åˆ é™¤äº† {deleted_count} ä¸ªå½•éŸ³æ–‡ä»¶")

        except Exception:
            # æ¸…ç†å¤±è´¥ä¸å½±å“å¯åŠ¨
            pass

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.recorder:
            self.recorder.cleanup()
        print("ğŸ§¹ èµ„æºæ¸…ç†å®Œæˆ")


def create_voice_assistant(use_baidu_tts: bool = False,
                          initial_volume: int = None,
                          voice_person: int = None,
                          recording_mode: str = "smart_vad") -> VoiceAssistant:
    """
    åˆ›å»ºè¯­éŸ³åŠ©æ‰‹å®ä¾‹

    Args:
        use_baidu_tts: æ˜¯å¦ä½¿ç”¨ç™¾åº¦TTS
        initial_volume: åˆå§‹éŸ³é‡
        voice_person: è¯­éŸ³äººç‰©
        recording_mode: å½•éŸ³æ¨¡å¼ (smart_vad, enter_key, fixed_duration)
    """
    return VoiceAssistant(use_baidu_tts, initial_volume, voice_person, recording_mode)
