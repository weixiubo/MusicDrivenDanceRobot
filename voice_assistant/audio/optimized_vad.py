#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„è‡ªé€‚åº”è¯­éŸ³æ´»åŠ¨æ£€æµ‹ç³»ç»Ÿ
ä¸“é—¨è§£å†³å™ªéŸ³å¹²æ‰°å’Œæ•æ„Ÿåº¦å¹³è¡¡é—®é¢˜
"""

import numpy as np
import time
from typing import Dict
from enum import Enum
import warnings

warnings.filterwarnings("ignore")

try:
    from ..config import config
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from voice_assistant.config import config

# å°è¯•å¯¼å…¥WebRTC VAD
try:
    import webrtcvad
    WEBRTC_AVAILABLE = True
except ImportError:
    WEBRTC_AVAILABLE = False


class VADState(Enum):
    """ç®€åŒ–çš„VADçŠ¶æ€"""
    IDLE = "idle"           # ç©ºé—²çŠ¶æ€
    DETECTING = "detecting" # æ£€æµ‹åˆ°å¯èƒ½çš„è¯­éŸ³
    SPEAKING = "speaking"   # ç¡®è®¤è¯­éŸ³çŠ¶æ€


# åˆ é™¤å¤æ‚çš„ç¯å¢ƒç›‘æ§ï¼Œç›´æ¥ä½¿ç”¨ç®€å•é˜ˆå€¼


class AdaptiveVAD:
    """è‡ªé€‚åº”è¯­éŸ³æ´»åŠ¨æ£€æµ‹å™¨"""
    
    def __init__(self,
                 sample_rate: int = 16000,
                 chunk_size: int = 1024,
                 base_volume_threshold: float = 10.0,  # æä½é˜ˆå€¼ï¼Œè¶…æ•æ„Ÿ
                 webrtc_aggressiveness: int = 0):      # æœ€æ•æ„Ÿçš„WebRTCè®¾ç½®
        """
        åˆå§‹åŒ–è‡ªé€‚åº”VAD
        
        Args:
            sample_rate: é‡‡æ ·ç‡
            chunk_size: éŸ³é¢‘å—å¤§å°
            base_volume_threshold: åŸºç¡€éŸ³é‡é˜ˆå€¼
            webrtc_aggressiveness: WebRTCæ¿€è¿›ç¨‹åº¦(0-3)
        """
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.base_volume_threshold = base_volume_threshold
        
        # åŠ¨æ€éŸ³é‡é˜ˆå€¼
        self.volume_threshold = base_volume_threshold
        self.base_volume_threshold = base_volume_threshold

        # ç¯å¢ƒå™ªéŸ³è‡ªé€‚åº”ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        self.noise_samples = []
        self.noise_baseline = 0.0
        self.noise_adaptation_frames = getattr(config, 'VAD_NOISE_ADAPTATION_FRAMES', 50)
        self.noise_multiplier = getattr(config, 'VAD_NOISE_MULTIPLIER', 3.0)
        self.enable_noise_adaptation = getattr(config, 'VAD_ENABLE_NOISE_ADAPTATION', True)
        
        # WebRTC VADï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.webrtc_vad = None
        self.webrtc_frame_size = int(sample_rate * 0.03)  # 30mså¸§
        if WEBRTC_AVAILABLE:
            try:
                self.webrtc_vad = webrtcvad.Vad(webrtc_aggressiveness)
                print("âœ… WebRTC VADå·²å¯ç”¨")
            except Exception as e:
                print(f"âš ï¸ WebRTC VADåˆå§‹åŒ–å¤±è´¥: {e}")
        
        # çŠ¶æ€ç®¡ç†
        self.state = VADState.IDLE
        self.speech_start_time = None
        self.last_speech_time = None

        # éŸ³é‡å˜åŒ–æ£€æµ‹ï¼ˆæ–°å¢ï¼‰
        self.volume_history = []
        self.volume_history_size = 30  # ä¿ç•™æœ€è¿‘30å¸§çš„éŸ³é‡ï¼ˆçº¦1.9ç§’ï¼‰
        self.volume_drop_threshold = 0.65  # éŸ³é‡ä¸‹é™65%è®¤ä¸ºæ˜¯é™éŸ³ï¼Œå¹³è¡¡é‡è¯»ä¿æŠ¤å’Œå“åº”é€Ÿåº¦

        # æ™ºèƒ½è¯­éŸ³è¿ç»­æ€§æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
        self.pause_detection_enabled = True  # å¯ç”¨åœé¡¿æ£€æµ‹
        self.pause_tolerance_frames = 8      # å…è®¸8å¸§ï¼ˆçº¦0.5ç§’ï¼‰çš„åœé¡¿
        self.pause_start_time = None         # åœé¡¿å¼€å§‹æ—¶é—´
        self.in_pause_state = False          # æ˜¯å¦åœ¨åœé¡¿çŠ¶æ€
        self.pause_recovery_frames = 2       # æ¢å¤è¯­éŸ³éœ€è¦è¿ç»­2å¸§
        
        # æ£€æµ‹å‚æ•°ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        self.detection_frames = getattr(config, 'VAD_DETECTION_FRAMES', 1)
        self.confirmation_frames = getattr(config, 'VAD_CONFIRMATION_FRAMES', 2)
        self.silence_frames_limit = getattr(config, 'VAD_SILENCE_FRAMES_LIMIT', 5)
        
        # å¸§è®¡æ•°å™¨
        self.speech_frame_count = 0
        self.silence_frame_count = 0
        
        # åˆ é™¤å¤æ‚çš„ç½®ä¿¡åº¦å¹³æ»‘
        
        # æ—¶åºå‚æ•°ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        self.min_speech_duration = getattr(config, 'VAD_MIN_SPEECH_DURATION', 0.3)
        self.max_silence_duration = getattr(config, 'VAD_MAX_SILENCE_DURATION', 0.8)
        self.max_speech_duration = getattr(config, 'VAD_MAX_SPEECH_DURATION', 8.0)
        
        print("ğŸ¤ è‡ªé€‚åº”VADç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"   åŸºç¡€é˜ˆå€¼: {self.base_volume_threshold}")
        print(f"   WebRTCå¯ç”¨: {'æ˜¯' if self.webrtc_vad else 'å¦'}")
    
    def _calculate_volume(self, audio_data: np.ndarray) -> float:
        """è®¡ç®—éŸ³é¢‘éŸ³é‡(RMS)"""
        if len(audio_data) == 0:
            return 0.0
        volume = float(np.sqrt(np.mean(audio_data.astype(np.float32) ** 2)))

        # æ›´æ–°éŸ³é‡å†å²ï¼ˆæ–°å¢ï¼‰
        self.volume_history.append(volume)
        if len(self.volume_history) > self.volume_history_size:
            self.volume_history.pop(0)

        # æ›´æ–°å™ªéŸ³åŸºçº¿ï¼ˆä»…åœ¨ç©ºé—²çŠ¶æ€æ—¶ä¸”å¯ç”¨è‡ªé€‚åº”ï¼‰
        if (self.enable_noise_adaptation and
            self.state == VADState.IDLE and
            len(self.noise_samples) < self.noise_adaptation_frames):
            self.noise_samples.append(volume)
            if len(self.noise_samples) == self.noise_adaptation_frames:
                self.noise_baseline = np.mean(self.noise_samples)
                # åŠ¨æ€è°ƒæ•´é˜ˆå€¼ï¼šå™ªéŸ³åŸºçº¿ * å€æ•°
                self.volume_threshold = max(self.base_volume_threshold, self.noise_baseline * self.noise_multiplier)
                print(f"ğŸ”§ å™ªéŸ³åŸºçº¿: {self.noise_baseline:.1f}, è°ƒæ•´é˜ˆå€¼: {self.volume_threshold:.1f}")

        return volume

    def _detect_volume_drop(self) -> bool:
        """æ£€æµ‹éŸ³é‡æ˜¯å¦æ˜¾è‘—ä¸‹é™ï¼ˆä¼˜åŒ–ç‰ˆæ™ºèƒ½æ£€æµ‹ï¼Œé¿å…é‡è¯»è¯¯åˆ¤ï¼‰"""
        if len(self.volume_history) < 15:  # éœ€è¦æ›´å¤šå†å²æ•°æ®é¿å…è¯¯åˆ¤
            return False

        # ä½¿ç”¨æ›´é•¿çš„æ—¶é—´çª—å£æ¥é¿å…é‡è¯»å¯¼è‡´çš„è¯¯åˆ¤
        recent_avg = np.mean(self.volume_history[-8:])
        previous_avg = np.mean(self.volume_history[-16:-8]) if len(self.volume_history) >= 16 else np.mean(self.volume_history[:-8])

        # é¢å¤–æ£€æŸ¥ï¼šå¦‚æœæœ€è¿‘æœ‰éŸ³é‡å³°å€¼ï¼Œè¯´æ˜å¯èƒ½æ˜¯é‡è¯»ï¼Œä¸åº”è¯¥ç»“æŸ
        recent_max = np.max(self.volume_history[-8:])
        overall_avg = np.mean(self.volume_history[-20:]) if len(self.volume_history) >= 20 else np.mean(self.volume_history)

        # å¦‚æœæœ€è¿‘æœ‰æ˜æ˜¾çš„éŸ³é‡å³°å€¼ï¼ˆé‡è¯»ï¼‰ï¼Œåˆ™ä¸è®¤ä¸ºæ˜¯é™éŸ³
        if recent_max > overall_avg * 1.5:  # æœ€è¿‘æœ‰è¶…è¿‡å¹³å‡éŸ³é‡1.5å€çš„å³°å€¼
            return False

        # å¦‚æœæœ€è¿‘éŸ³é‡æ¯”ä¹‹å‰éŸ³é‡ä¸‹é™è¶…è¿‡é˜ˆå€¼ï¼Œè®¤ä¸ºæ˜¯é™éŸ³
        if previous_avg > 0:
            drop_ratio = (previous_avg - recent_avg) / previous_avg
            # å¯é€‰è°ƒè¯•ä¿¡æ¯ï¼ˆä»…åœ¨é…ç½®å¯ç”¨æ—¶æ˜¾ç¤ºï¼‰
            if getattr(config, 'VAD_ENABLE_DEBUG', False) and self.state == VADState.SPEAKING and drop_ratio > 0.1:
                if hasattr(self, '_volume_debug_count'):
                    self._volume_debug_count += 1
                else:
                    self._volume_debug_count = 1
                if self._volume_debug_count % 20 == 0:  # æ¯20å¸§æ‰“å°ä¸€æ¬¡
                    print(f"ğŸ” éŸ³é‡: ä¹‹å‰={previous_avg:.3f}, æœ€è¿‘={recent_avg:.3f}, ä¸‹é™={drop_ratio:.2f}, å³°å€¼={recent_max:.3f}")

            return drop_ratio > self.volume_drop_threshold

        return False

    def _detect_speech_pause(self, is_speech_frame: bool) -> bool:
        """
        ç®€åŒ–çš„æ™ºèƒ½è¯­éŸ³åœé¡¿æ£€æµ‹
        åªåœ¨è¿ç»­é™éŸ³æ—¶é—´è¿‡é•¿æ—¶æ‰ç»“æŸè¯­éŸ³

        Returns:
            bool: æ˜¯å¦åº”è¯¥ç»“æŸè¯­éŸ³ï¼ˆTrue=ç»“æŸï¼ŒFalse=ç»§ç»­ç­‰å¾…ï¼‰
        """
        if not self.pause_detection_enabled:
            return False

        current_time = time.time()

        if is_speech_frame:
            # æ£€æµ‹åˆ°è¯­éŸ³ï¼Œé‡ç½®åœé¡¿çŠ¶æ€
            if self.in_pause_state:
                self.in_pause_state = False
                self.pause_start_time = None
                print(f"ğŸ”„ è¯­éŸ³æ¢å¤ï¼Œç»§ç»­å½•éŸ³")

        else:
            # æ£€æµ‹åˆ°é™éŸ³
            if not self.in_pause_state:
                # å¼€å§‹åœé¡¿
                self.in_pause_state = True
                self.pause_start_time = current_time

            elif self.pause_start_time:
                # æ£€æŸ¥åœé¡¿æ—¶é•¿
                pause_duration = current_time - self.pause_start_time

                if pause_duration >= 1.5:  # åœé¡¿è¶…è¿‡1.5ç§’ç»“æŸï¼Œå¹³è¡¡é•¿å¥æ”¯æŒå’Œå“åº”é€Ÿåº¦
                    print(f"â¹ï¸ åœé¡¿æ—¶é—´è¿‡é•¿({pause_duration:.1f}s)ï¼Œç¡®è®¤è¯­éŸ³ç»“æŸ")
                    return True

        return False

    def _webrtc_detect(self, audio_data: np.ndarray) -> float:
        """ä½¿ç”¨WebRTC VADæ£€æµ‹"""
        if not self.webrtc_vad:
            return 0.0
        
        try:
            # ç¡®ä¿æ•°æ®é•¿åº¦æ­£ç¡®
            if len(audio_data) < self.webrtc_frame_size:
                padded = np.zeros(self.webrtc_frame_size, dtype=audio_data.dtype)
                padded[:len(audio_data)] = audio_data
                audio_data = padded
            elif len(audio_data) > self.webrtc_frame_size:
                audio_data = audio_data[:self.webrtc_frame_size]
            
            # è½¬æ¢ä¸º16ä½æ•´æ•°
            audio_int16 = (audio_data * 32767).astype(np.int16)
            frame_bytes = audio_int16.tobytes()
            
            # WebRTCæ£€æµ‹
            is_speech = self.webrtc_vad.is_speech(frame_bytes, self.sample_rate)
            return 0.8 if is_speech else 0.0
            
        except Exception:
            return 0.0
    
    def _calculate_confidence(self, volume: float, webrtc_confidence: float) -> float:
        """æ™ºèƒ½ç½®ä¿¡åº¦è®¡ç®— - å½»åº•ä¿®å¤WebRTCæƒé‡å¯¼è‡´çš„å»¶è¿Ÿé—®é¢˜"""
        # éŸ³é‡ç½®ä¿¡åº¦ï¼ˆä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼ï¼‰
        if volume < self.volume_threshold:
            volume_confidence = 0.0
        else:
            # è¶…è¿‡é˜ˆå€¼åï¼Œéœ€è¦æ˜¾è‘—è¶…è¿‡æ‰è®¤ä¸ºæ˜¯è¯­éŸ³
            volume_confidence = min((volume - self.volume_threshold) / (self.volume_threshold * 2), 1.0)

        # ç»¼åˆç½®ä¿¡åº¦ - ä»é…ç½®æ–‡ä»¶è¯»å–æƒé‡
        webrtc_weight = getattr(config, 'VAD_WEBRTC_WEIGHT', 0.4)
        volume_weight = getattr(config, 'VAD_VOLUME_WEIGHT', 0.6)

        if self.webrtc_vad and webrtc_weight > 0:
            # å½»åº•ä¿®å¤ï¼šåœ¨SPEAKINGçŠ¶æ€ä¸‹ï¼Œå¦‚æœéŸ³é‡ç½®ä¿¡åº¦ä¸º0ï¼Œç›´æ¥å¿½ç•¥WebRTC
            # è¿™æ ·å¯ä»¥ç¡®ä¿é™éŸ³æ—¶èƒ½å¤Ÿå¿«é€Ÿç»“æŸè¯­éŸ³æ£€æµ‹
            if self.state == VADState.SPEAKING and volume_confidence == 0.0:
                # åœ¨è¯­éŸ³çŠ¶æ€ä¸‹é‡åˆ°é™éŸ³ï¼Œå®Œå…¨å¿½ç•¥WebRTCï¼Œåªçœ‹éŸ³é‡
                confidence = volume_confidence
            elif volume_confidence == 0.0:
                # éè¯­éŸ³çŠ¶æ€ä¸‹çš„é™éŸ³ï¼ŒWebRTCæƒé‡é™ä½åˆ°5%
                effective_webrtc_weight = webrtc_weight * 0.05
                effective_volume_weight = 1.0 - effective_webrtc_weight
                confidence = effective_webrtc_weight * webrtc_confidence + effective_volume_weight * volume_confidence
            else:
                # æœ‰éŸ³é‡æ—¶ï¼Œä½¿ç”¨æ­£å¸¸æƒé‡
                confidence = webrtc_weight * webrtc_confidence + volume_weight * volume_confidence
        else:
            # æ²¡æœ‰WebRTCæ—¶ï¼Œä»…ä½¿ç”¨éŸ³é‡
            confidence = volume_confidence

        return confidence

    def _update_state_machine(self, confidence: float) -> bool:
        """æ›´æ–°çŠ¶æ€æœºï¼Œè¿”å›æ˜¯å¦å‘ç”ŸçŠ¶æ€å˜åŒ–"""
        current_time = time.time()
        state_changed = False
        # ä»é…ç½®æ–‡ä»¶è¯»å–ç½®ä¿¡åº¦é˜ˆå€¼
        confidence_threshold = getattr(config, 'VAD_CONFIDENCE_THRESHOLD', 0.2)
        is_speech_frame = confidence > confidence_threshold

        # å¯é€‰è°ƒè¯•ä¿¡æ¯ï¼ˆä»…åœ¨é…ç½®å¯ç”¨æ—¶æ˜¾ç¤ºï¼‰
        if getattr(config, 'VAD_ENABLE_DEBUG', False):
            if hasattr(self, '_debug_frame_count'):
                self._debug_frame_count += 1
            else:
                self._debug_frame_count = 1

            if self._debug_frame_count % 50 == 0 and self.state == VADState.SPEAKING:
                print(f"ğŸ” è°ƒè¯•: ç½®ä¿¡åº¦={confidence:.3f}, é˜ˆå€¼={confidence_threshold}, é™éŸ³å¸§={self.silence_frame_count}")

        if is_speech_frame:
            self.speech_frame_count += 1
            self.silence_frame_count = 0
            self.last_speech_time = current_time
        else:
            self.speech_frame_count = 0
            self.silence_frame_count += 1



        # çŠ¶æ€è½¬æ¢é€»è¾‘ï¼ˆæ›´æ•æ„Ÿçš„åˆ¤æ–­ï¼‰
        if self.state == VADState.IDLE:
            if self.speech_frame_count >= self.detection_frames:
                self.state = VADState.DETECTING

        elif self.state == VADState.DETECTING:
            if self.speech_frame_count >= self.confirmation_frames:
                self.state = VADState.SPEAKING
                self.speech_start_time = current_time
                state_changed = True
                print(f"ğŸ”´ è¯­éŸ³å¼€å§‹ (ç½®ä¿¡åº¦: {confidence:.2f})")
            elif self.silence_frame_count > 5:  # é™ä½é™éŸ³å®¹å¿åº¦
                self.state = VADState.IDLE

        elif self.state == VADState.SPEAKING:
            speech_duration = current_time - self.speech_start_time

            # å¼ºåˆ¶è¶…æ—¶æ£€æŸ¥
            if speech_duration >= self.max_speech_duration:
                self.state = VADState.IDLE
                state_changed = True
                print(f"â° è¯­éŸ³å¼ºåˆ¶ç»“æŸ (è¶…æ—¶: {speech_duration:.1f}ç§’)")
            else:
                # æ™ºèƒ½åœé¡¿æ£€æµ‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
                should_end_by_pause = self._detect_speech_pause(is_speech_frame)

                # ä¼ ç»Ÿæ£€æµ‹æ–¹æ³•ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
                should_end_by_silence = self.silence_frame_count >= self.silence_frames_limit
                should_end_by_volume = self._detect_volume_drop()

                # ç®€åŒ–åˆ¤æ–­é€»è¾‘ï¼šä»»ä½•ä¸€ç§æ£€æµ‹æ–¹æ³•è§¦å‘éƒ½å¯ä»¥ç»“æŸ
                if should_end_by_pause or should_end_by_silence or should_end_by_volume:
                    # æ£€æŸ¥æœ€å°è¯­éŸ³æ—¶é•¿
                    if speech_duration >= self.min_speech_duration:
                        self.state = VADState.IDLE
                        state_changed = True

                        # æ ¹æ®ç»“æŸåŸå› æ˜¾ç¤ºä¸åŒä¿¡æ¯
                        if should_end_by_pause:
                            print(f"â¹ï¸ è¯­éŸ³ç»“æŸ (æ™ºèƒ½åœé¡¿æ£€æµ‹, æ—¶é•¿: {speech_duration:.1f}ç§’)")
                        elif should_end_by_volume:
                            print(f"â¹ï¸ è¯­éŸ³ç»“æŸ (éŸ³é‡ä¸‹é™æ£€æµ‹, æ—¶é•¿: {speech_duration:.1f}ç§’)")
                        else:
                            print(f"â¹ï¸ è¯­éŸ³ç»“æŸ (é™éŸ³æ£€æµ‹, æ—¶é•¿: {speech_duration:.1f}ç§’)")
                    else:
                        # è¯­éŸ³å¤ªçŸ­ï¼Œç»§ç»­ç­‰å¾…
                        self.silence_frame_count = max(0, self.silence_frame_count - 3)

        return state_changed

    def detect(self, audio_data: np.ndarray) -> Dict:
        """
        æ£€æµ‹è¯­éŸ³æ´»åŠ¨

        Returns:
            dict: {
                'is_speech': bool,
                'confidence': float,
                'state': str,
                'state_changed': bool,
                'debug_info': dict
            }
        """
        # è®¡ç®—éŸ³é¢‘ç‰¹å¾
        volume = self._calculate_volume(audio_data)
        webrtc_confidence = self._webrtc_detect(audio_data)

        # ç®€å•æ£€æµ‹ï¼Œä¸éœ€è¦ç¯å¢ƒç›‘æ§

        # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
        confidence = self._calculate_confidence(volume, webrtc_confidence)

        # æ›´æ–°çŠ¶æ€æœº
        state_changed = self._update_state_machine(confidence)

        # è®¡ç®—è¯­éŸ³æŒç»­æ—¶é—´
        speech_duration = 0.0
        if self.speech_start_time:
            speech_duration = time.time() - self.speech_start_time

        return {
            'is_speech': self.state == VADState.SPEAKING,
            'confidence': confidence,
            'state': self.state.value,
            'state_changed': state_changed,
            'speech_duration': speech_duration,
            'debug_info': {
                'volume': volume,
                'webrtc_confidence': webrtc_confidence,
                'threshold': self.volume_threshold,
                'speech_frames': self.speech_frame_count,
                'silence_frames': self.silence_frame_count
            }
        }

    def reset(self):
        """é‡ç½®VADçŠ¶æ€"""
        self.state = VADState.IDLE
        self.speech_frame_count = 0
        self.silence_frame_count = 0
        self.speech_start_time = None
        self.last_speech_time = None

        # é‡ç½®æ™ºèƒ½åœé¡¿æ£€æµ‹çŠ¶æ€
        self.pause_start_time = None
        self.in_pause_state = False
        if hasattr(self, '_recovery_frame_count'):
            self._recovery_frame_count = 0
        if hasattr(self, '_volume_debug_count'):
            self._volume_debug_count = 0

        print("ğŸ”„ VADçŠ¶æ€å·²é‡ç½®")

    def get_status(self) -> Dict:
        """è·å–VADçŠ¶æ€ä¿¡æ¯"""
        return {
            'state': self.state.value,
            'webrtc_available': self.webrtc_vad is not None,
            'volume_threshold': self.volume_threshold,
            'speech_duration': (
                time.time() - self.speech_start_time
                if self.speech_start_time else 0.0
            )
        }

    def adjust_sensitivity(self, factor: float):
        """è°ƒæ•´VADæ•æ„Ÿåº¦"""
        self.volume_threshold *= factor
        print(f"ğŸ›ï¸ VADæ•æ„Ÿåº¦å·²è°ƒæ•´ï¼Œæ–°é˜ˆå€¼: {self.volume_threshold:.1f}")


def create_optimized_vad(**kwargs) -> AdaptiveVAD:
    """åˆ›å»ºä¼˜åŒ–çš„è‡ªé€‚åº”VADå®ä¾‹"""
    return AdaptiveVAD(**kwargs)
