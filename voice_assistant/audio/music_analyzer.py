#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®æ—¶éŸ³ä¹åˆ†ææ¨¡å—
ä½¿ç”¨librosaè¿›è¡ŒéŸ³ä¹ç‰¹å¾æå–å’ŒèŠ‚æ‹æ£€æµ‹
"""

import numpy as np
import time
import threading
import queue
from typing import Dict, Optional, Callable
from dataclasses import dataclass

try:
    import librosa
    LIBROSA_AVAILABLE = True
except ImportError:
    LIBROSA_AVAILABLE = False
    print("âš ï¸ librosaæœªå®‰è£…ï¼ŒéŸ³ä¹åˆ†æåŠŸèƒ½å°†è¢«ç¦ç”¨")

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False

from ..config import config

try:
    from .music_structure_analyzer import create_structure_analyzer, MusicStructureAnalyzer
    STRUCTURE_ANALYSIS_AVAILABLE = True
except ImportError:
    STRUCTURE_ANALYSIS_AVAILABLE = False
    MusicStructureAnalyzer = None


@dataclass
class MusicFeatures:
    """éŸ³ä¹ç‰¹å¾æ•°æ®ç±»"""
    tempo: float = 0.0              # èŠ‚æ‹é€Ÿåº¦ (BPM)
    beat_strength: float = 0.0      # èŠ‚æ‹å¼ºåº¦
    energy: float = 0.0             # éŸ³é¢‘èƒ½é‡
    spectral_centroid: float = 0.0  # é¢‘è°±é‡å¿ƒ
    zero_crossing_rate: float = 0.0 # è¿‡é›¶ç‡
    mfcc_mean: np.ndarray = None    # MFCCç‰¹å¾å‡å€¼
    onset_strength: float = 0.0     # èµ·å§‹å¼ºåº¦
    rhythm_pattern: str = "steady"  # èŠ‚å¥æ¨¡å¼
    mood: str = "neutral"           # éŸ³ä¹æƒ…ç»ª
    timestamp: float = 0.0          # æ—¶é—´æˆ³

    # æ–°å¢ï¼šéŸ³ä¹ç»“æ„ä¿¡æ¯
    segment_type: str = "unknown"   # éŸ³ä¹æ®µè½ç±»å‹
    segment_intensity: float = 0.5  # æ®µè½å¼ºåº¦
    energy_trend: str = "stable"    # èƒ½é‡è¶‹åŠ¿
    structure_confidence: float = 0.5  # ç»“æ„è¯†åˆ«ç½®ä¿¡åº¦


class MusicAnalyzer:
    """å®æ—¶éŸ³ä¹åˆ†æå™¨"""
    
    def __init__(self, 
                 sample_rate: int = 22050,
                 chunk_size: int = 1024,
                 analysis_window: float = 2.0,
                 enable_analysis: bool = True):
        """
        åˆå§‹åŒ–éŸ³ä¹åˆ†æå™¨
        
        Args:
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
            chunk_size: éŸ³é¢‘å—å¤§å°
            analysis_window: åˆ†æçª—å£æ—¶é•¿ï¼ˆç§’ï¼‰
            enable_analysis: æ˜¯å¦å¯ç”¨åˆ†æåŠŸèƒ½
        """
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.analysis_window = analysis_window
        self.enable_analysis = enable_analysis and LIBROSA_AVAILABLE
        
        # éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = queue.Queue(maxsize=100)
        self.analysis_buffer = []
        self.buffer_duration = 0.0
        
        # åˆ†æç»“æœ
        self.current_features = MusicFeatures()
        self.features_history = []
        self.max_history = 10
        
        # çº¿ç¨‹æ§åˆ¶
        self.is_analyzing = False
        self.analysis_thread = None
        self.stop_event = threading.Event()
        
        # å›è°ƒå‡½æ•°
        self.feature_callback: Optional[Callable] = None

        # éŸ³ä¹ç»“æ„åˆ†æå™¨
        self.structure_analyzer = None
        if STRUCTURE_ANALYSIS_AVAILABLE and enable_analysis:
            try:
                self.structure_analyzer = create_structure_analyzer(enable_analysis)
                print("âœ… éŸ³ä¹ç»“æ„åˆ†æå™¨å·²é›†æˆ")
            except Exception as e:
                print(f"âš ï¸ éŸ³ä¹ç»“æ„åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        # éŸ³é¢‘è®¾å¤‡
        self.audio = None
        self.stream = None
        
        if not self.enable_analysis:
            print("âš ï¸ éŸ³ä¹åˆ†æåŠŸèƒ½å·²ç¦ç”¨ï¼ˆlibrosaä¸å¯ç”¨ï¼‰")
        else:
            print("âœ… éŸ³ä¹åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def set_feature_callback(self, callback: Callable[[MusicFeatures], None]):
        """è®¾ç½®ç‰¹å¾æ›´æ–°å›è°ƒå‡½æ•°"""
        self.feature_callback = callback
    
    def start_analysis(self) -> bool:
        """å¼€å§‹éŸ³ä¹åˆ†æ"""
        if not self.enable_analysis:
            print("âš ï¸ éŸ³ä¹åˆ†æåŠŸèƒ½æœªå¯ç”¨")
            return False
            
        if self.is_analyzing:
            print("âš ï¸ éŸ³ä¹åˆ†æå·²åœ¨è¿è¡Œ")
            return False
        
        if not PYAUDIO_AVAILABLE:
            print("âŒ pyaudioä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒéŸ³ä¹åˆ†æ")
            return False
        
        try:
            # åˆå§‹åŒ–éŸ³é¢‘è®¾å¤‡
            self.audio = pyaudio.PyAudio()
            
            # åˆ›å»ºéŸ³é¢‘æµï¼ˆä½¿ç”¨è¾ƒä½çš„é‡‡æ ·ç‡ä»¥å‡å°‘è®¡ç®—è´Ÿæ‹…ï¼‰
            self.stream = self.audio.open(
                format=pyaudio.paFloat32,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size,
                stream_callback=self._audio_callback
            )
            
            # å¯åŠ¨åˆ†æçº¿ç¨‹
            self.is_analyzing = True
            self.stop_event.clear()
            self.analysis_thread = threading.Thread(
                target=self._analysis_loop,
                daemon=True
            )
            self.analysis_thread.start()
            
            # å¼€å§‹éŸ³é¢‘æµ
            self.stream.start_stream()
            
            print("ğŸµ éŸ³ä¹åˆ†æå·²å¯åŠ¨")
            return True
            
        except Exception as e:
            print(f"âŒ å¯åŠ¨éŸ³ä¹åˆ†æå¤±è´¥: {e}")
            self.stop_analysis()
            return False
    
    def stop_analysis(self):
        """åœæ­¢éŸ³ä¹åˆ†æ"""
        if not self.is_analyzing:
            return
        
        print("â¹ï¸ åœæ­¢éŸ³ä¹åˆ†æ")
        
        # åœæ­¢çº¿ç¨‹
        self.is_analyzing = False
        self.stop_event.set()
        
        # åœæ­¢éŸ³é¢‘æµ
        if self.stream:
            try:
                self.stream.stop_stream()
                self.stream.close()
            except:
                pass
            self.stream = None
        
        if self.audio:
            try:
                self.audio.terminate()
            except:
                pass
            self.audio = None
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.analysis_thread and self.analysis_thread.is_alive():
            self.analysis_thread.join(timeout=2)
        
        # æ¸…ç†ç¼“å†²åŒº
        while not self.audio_buffer.empty():
            try:
                self.audio_buffer.get_nowait()
            except:
                break

        self.analysis_buffer.clear()

        # é‡ç½®ç»“æ„åˆ†æå™¨
        if self.structure_analyzer:
            self.structure_analyzer.reset_analysis()

        print("âœ… éŸ³ä¹åˆ†æå·²åœæ­¢")
    
    def _audio_callback(self, in_data, frame_count, time_info, status):
        """éŸ³é¢‘å›è°ƒå‡½æ•°"""
        if self.is_analyzing:
            try:
                # å°†éŸ³é¢‘æ•°æ®æ”¾å…¥ç¼“å†²åŒº
                audio_data = np.frombuffer(in_data, dtype=np.float32)
                if not self.audio_buffer.full():
                    self.audio_buffer.put(audio_data)
            except:
                pass
        
        return (None, pyaudio.paContinue)
    
    def _analysis_loop(self):
        """éŸ³ä¹åˆ†æä¸»å¾ªç¯"""
        print("ğŸ”„ éŸ³ä¹åˆ†æå¾ªç¯å¯åŠ¨")
        
        while self.is_analyzing and not self.stop_event.is_set():
            try:
                # ä»ç¼“å†²åŒºè·å–éŸ³é¢‘æ•°æ®
                if not self.audio_buffer.empty():
                    audio_chunk = self.audio_buffer.get(timeout=0.1)
                    self._process_audio_chunk(audio_chunk)
                else:
                    time.sleep(0.05)  # çŸ­æš‚ä¼‘çœ 
                    
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âš ï¸ éŸ³ä¹åˆ†æé”™è¯¯: {e}")
                time.sleep(0.1)
        
        print("ğŸ”„ éŸ³ä¹åˆ†æå¾ªç¯ç»“æŸ")
    
    def _process_audio_chunk(self, audio_chunk: np.ndarray):
        """å¤„ç†éŸ³é¢‘å—"""
        # æ·»åŠ åˆ°åˆ†æç¼“å†²åŒº
        self.analysis_buffer.extend(audio_chunk)
        self.buffer_duration += len(audio_chunk) / self.sample_rate
        
        # å½“ç¼“å†²åŒºè¾¾åˆ°åˆ†æçª—å£å¤§å°æ—¶è¿›è¡Œåˆ†æ
        if self.buffer_duration >= self.analysis_window:
            self._analyze_buffer()
            
            # ä¿ç•™ä¸€åŠæ•°æ®ä½œä¸ºé‡å çª—å£
            overlap_samples = len(self.analysis_buffer) // 2
            self.analysis_buffer = self.analysis_buffer[-overlap_samples:]
            self.buffer_duration = len(self.analysis_buffer) / self.sample_rate
    
    def _analyze_buffer(self):
        """åˆ†æéŸ³é¢‘ç¼“å†²åŒº"""
        if len(self.analysis_buffer) < self.sample_rate * 0.5:  # è‡³å°‘0.5ç§’æ•°æ®
            return
        
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_data = np.array(self.analysis_buffer, dtype=np.float32)
            
            # æå–éŸ³ä¹ç‰¹å¾
            features = self._extract_features(audio_data)
            
            # æ›´æ–°å½“å‰ç‰¹å¾
            self.current_features = features
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.features_history.append(features)
            if len(self.features_history) > self.max_history:
                self.features_history.pop(0)
            
            # è°ƒç”¨å›è°ƒå‡½æ•°
            if self.feature_callback:
                try:
                    self.feature_callback(features)
                except Exception as e:
                    print(f"âš ï¸ ç‰¹å¾å›è°ƒå‡½æ•°é”™è¯¯: {e}")
                    
        except Exception as e:
            print(f"âš ï¸ éŸ³é¢‘åˆ†æé”™è¯¯: {e}")
    
    def _extract_features(self, audio_data: np.ndarray) -> MusicFeatures:
        """æå–éŸ³ä¹ç‰¹å¾"""
        features = MusicFeatures()
        features.timestamp = time.time()
        
        try:
            # åŸºç¡€ç‰¹å¾
            features.energy = float(np.mean(audio_data ** 2))
            features.zero_crossing_rate = float(np.mean(librosa.feature.zero_crossing_rate(audio_data)[0]))
            
            # é¢‘è°±ç‰¹å¾
            if len(audio_data) > 512:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
                spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=self.sample_rate)[0]
                features.spectral_centroid = float(np.mean(spectral_centroids))
                
                # MFCCç‰¹å¾
                mfcc = librosa.feature.mfcc(y=audio_data, sr=self.sample_rate, n_mfcc=13)
                features.mfcc_mean = np.mean(mfcc, axis=1)
                
                # èŠ‚æ‹å’ŒèŠ‚å¥åˆ†æ
                try:
                    tempo, beats = librosa.beat.beat_track(y=audio_data, sr=self.sample_rate)
                    features.tempo = float(tempo)
                    
                    # è®¡ç®—èŠ‚æ‹å¼ºåº¦
                    onset_envelope = librosa.onset.onset_strength(y=audio_data, sr=self.sample_rate)
                    features.onset_strength = float(np.mean(onset_envelope))
                    features.beat_strength = float(np.std(onset_envelope))
                    
                except:
                    # å¦‚æœèŠ‚æ‹æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    features.tempo = 120.0
                    features.beat_strength = 0.5
                    features.onset_strength = 0.5
            
            # åˆ†æèŠ‚å¥æ¨¡å¼å’Œæƒ…ç»ª
            features.rhythm_pattern = self._analyze_rhythm_pattern(features)
            features.mood = self._analyze_mood(features)

            # é›†æˆéŸ³ä¹ç»“æ„åˆ†æ
            if self.structure_analyzer:
                try:
                    # ä¸ºç»“æ„åˆ†æå™¨å‡†å¤‡ç‰¹å¾æ•°æ®
                    structure_features = {
                        'rms_energy': features.energy,
                        'tempo': features.tempo,
                        'onset_strength': features.onset_strength,
                        'spectral_centroid': features.spectral_centroid,
                        'timestamp': features.timestamp
                    }

                    # æ›´æ–°ç»“æ„åˆ†æ
                    structure_state = self.structure_analyzer.update_structure_analysis(structure_features)
                    structure_info = self.structure_analyzer.get_current_structure_info()

                    # å°†ç»“æ„ä¿¡æ¯æ·»åŠ åˆ°ç‰¹å¾ä¸­
                    features.segment_type = structure_info.get('segment_type', 'unknown')
                    features.segment_intensity = structure_info.get('intensity', 0.5)
                    features.energy_trend = structure_info.get('energy_trend', 'stable')
                    features.structure_confidence = structure_info.get('confidence', 0.5)

                except Exception as e:
                    print(f"âš ï¸ ç»“æ„åˆ†ææ›´æ–°å¤±è´¥: {e}")
                    # ä½¿ç”¨é»˜è®¤å€¼
                    features.segment_type = "unknown"
                    features.segment_intensity = 0.5
                    features.energy_trend = "stable"
                    features.structure_confidence = 0.3
            
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾æå–é”™è¯¯: {e}")
            # è¿”å›é»˜è®¤ç‰¹å¾
            features.tempo = 120.0
            features.energy = 0.1
            features.rhythm_pattern = "steady"
            features.mood = "neutral"
        
        return features
    
    def _analyze_rhythm_pattern(self, features: MusicFeatures) -> str:
        """åˆ†æèŠ‚å¥æ¨¡å¼"""
        if features.tempo > 140:
            return "fast"
        elif features.tempo < 80:
            return "slow"
        elif features.beat_strength > 0.7:
            return "strong"
        elif features.beat_strength < 0.3:
            return "gentle"
        else:
            return "steady"
    
    def _analyze_mood(self, features: MusicFeatures) -> str:
        """åˆ†æéŸ³ä¹æƒ…ç»ª"""
        if features.energy > 0.5 and features.tempo > 120:
            return "energetic"
        elif features.energy < 0.2 and features.tempo < 90:
            return "calm"
        elif features.spectral_centroid > 2000:
            return "bright"
        elif features.spectral_centroid < 1000:
            return "dark"
        else:
            return "neutral"
    
    def get_current_features(self) -> MusicFeatures:
        """è·å–å½“å‰éŸ³ä¹ç‰¹å¾"""
        return self.current_features
    
    def get_average_features(self, window: int = 5) -> MusicFeatures:
        """è·å–å¹³å‡éŸ³ä¹ç‰¹å¾"""
        if not self.features_history:
            return self.current_features
        
        recent_features = self.features_history[-window:]
        if not recent_features:
            return self.current_features
        
        # è®¡ç®—å¹³å‡å€¼
        avg_features = MusicFeatures()
        avg_features.tempo = np.mean([f.tempo for f in recent_features])
        avg_features.energy = np.mean([f.energy for f in recent_features])
        avg_features.beat_strength = np.mean([f.beat_strength for f in recent_features])
        avg_features.spectral_centroid = np.mean([f.spectral_centroid for f in recent_features])
        avg_features.zero_crossing_rate = np.mean([f.zero_crossing_rate for f in recent_features])
        avg_features.onset_strength = np.mean([f.onset_strength for f in recent_features])
        
        # ä½¿ç”¨æœ€æ–°çš„åˆ†ç±»ç‰¹å¾
        avg_features.rhythm_pattern = recent_features[-1].rhythm_pattern
        avg_features.mood = recent_features[-1].mood
        avg_features.timestamp = time.time()
        
        return avg_features


def create_music_analyzer(enable_analysis: bool = True) -> MusicAnalyzer:
    """åˆ›å»ºéŸ³ä¹åˆ†æå™¨å®ä¾‹"""
    return MusicAnalyzer(
        sample_rate=22050,  # ä½¿ç”¨è¾ƒä½é‡‡æ ·ç‡å‡å°‘è®¡ç®—è´Ÿæ‹…
        chunk_size=1024,
        analysis_window=2.0,
        enable_analysis=enable_analysis
    )
